{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "import mrcnn.visualize\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class label names from disk, one label per line\n",
    "# CLASS_NAMES = open(\"coco_labels.txt\").read().strip().split(\"\\n\")\n",
    "\n",
    "CLASS_NAMES = ['breech_face', 'firing_pin_impression', 'firing_pin_drag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        35\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  1024\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               10\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class SimpleConfig(mrcnn.config.Config):\n",
    "#     # Give the configuration a recognizable name\n",
    "#     NAME = \"coco_inference\"\n",
    "    \n",
    "#     # set the number of GPUs to use along with the number of images per GPU\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 1\n",
    "\n",
    "#     # Number of classes = number of classes + 1 (+1 for the background). The background class is named BG\n",
    "#     NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# config = SimpleConfig()\n",
    "# config.display()\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer #391 (named \"mrcnn_bbox_fc\"), weight <tf.Variable 'mrcnn_bbox_fc_7/kernel:0' shape=(1024, 324) dtype=float32> has shape (1024, 324), but the saved weight has shape (1024, 16).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m mrcnn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mMaskRCNN(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      4\u001b[0m                              config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m      5\u001b[0m                              model_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the weights into the model.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Download the mask_rcnn_coco.h5 file from this link: https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask_rcnn_experiment_0005.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Misc\\DDave_Forensics\\maskrcnn\\mrcnn\\model.py:2144\u001b[0m, in \u001b[0;36mMaskRCNN.load_weights\u001b[1;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[0;32m   2141\u001b[0m     layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m l: l\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude, layers)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m by_name:\n\u001b[1;32m-> 2144\u001b[0m     \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights_from_hdf5_group_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2146\u001b[0m     hdf5_format\u001b[38;5;241m.\u001b[39mload_weights_from_hdf5_group(f, layers)\n",
      "File \u001b[1;32mc:\\Users\\Sakuta\\.conda\\envs\\maskrcnn-tf2\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:790\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[1;34m(f, layers, skip_mismatch)\u001b[0m\n\u001b[0;32m    784\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkipping loading of weights for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    785\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(layer\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m due to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    786\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmismatch in shape (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    787\u001b[0m                         symbolic_weights[i]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    788\u001b[0m                         weight_values[i]\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer #\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    791\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m), weight \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(symbolic_weights[i]) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    792\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(backend\u001b[38;5;241m.\u001b[39mint_shape(\n\u001b[0;32m    793\u001b[0m                        symbolic_weights[i])) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    794\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, but the saved weight has shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    795\u001b[0m                    \u001b[38;5;28mstr\u001b[39m(weight_values[i]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m   weight_value_tuples\u001b[38;5;241m.\u001b[39mappend((symbolic_weights[i], weight_values[i]))\n",
      "\u001b[1;31mValueError\u001b[0m: Layer #391 (named \"mrcnn_bbox_fc\"), weight <tf.Variable 'mrcnn_bbox_fc_7/kernel:0' shape=(1024, 324) dtype=float32> has shape (1024, 324), but the saved weight has shape (1024, 16)."
     ]
    }
   ],
   "source": [
    "# Initialize the Mask R-CNN model for inference and then load the weights.\n",
    "# This step builds the Keras model architecture.\n",
    "model = mrcnn.model.MaskRCNN(mode=\"inference\", \n",
    "                             config=config,\n",
    "                             model_dir=os.getcwd())\n",
    "\n",
    "# Load the weights into the model.\n",
    "# Download the mask_rcnn_coco.h5 file from this link: https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "model.load_weights(filepath=\"mask_rcnn_experiment_0005.h5\", \n",
    "                   by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sakuta\\.conda\\envs\\maskrcnn-tf2\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m r \u001b[38;5;241m=\u001b[39m r[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Visualize the detected objects.\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmrcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrois\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mclass_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Misc\\DDave_Forensics\\maskrcnn\\mrcnn\\visualize.py:149\u001b[0m, in \u001b[0;36mdisplay_instances\u001b[1;34m(image, boxes, masks, class_ids, class_names, scores, title, figsize, figAx, show_mask, show_bbox, show_caption, colors, captions)\u001b[0m\n\u001b[0;32m    147\u001b[0m     class_id \u001b[38;5;241m=\u001b[39m class_ids[i]\n\u001b[0;32m    148\u001b[0m     score \u001b[38;5;241m=\u001b[39m scores[i] \u001b[38;5;28;01mif\u001b[39;00m scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mclass_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    150\u001b[0m     caption \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(label, score) \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;28;01melse\u001b[39;00m label\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# load the input image, convert it from BGR to RGB channel\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform a forward pass of the network to obtain the results\n",
    "r = model.detect([image], verbose=0)\n",
    "\n",
    "# Get the results for the first image.\n",
    "r = r[0]\n",
    "\n",
    "# Visualize the detected objects.\n",
    "mrcnn.visualize.display_instances(image=image, \n",
    "                                  boxes=r['rois'], \n",
    "                                  masks=r['masks'], \n",
    "                                  class_ids=r['class_ids'], \n",
    "                                  class_names=CLASS_NAMES, \n",
    "                                  scores=r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
